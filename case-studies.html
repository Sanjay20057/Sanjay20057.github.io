<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Case Studies | Sanjay Sharma</title>

  <!-- Main Portfolio CSS -->
  <link rel="stylesheet" href="/static/style.css" />
  <script defer src="/static/script.js"></script>
  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: "Inter", sans-serif;
      background: linear-gradient(135deg, #eef2ff, #f8fafc);
    }

    /* Layout */
    .case-layout {
      display: grid;
      grid-template-columns: 280px 1fr;
      min-height: 100vh;
    }

    /* Sidebar */
    .case-sidebar {
      padding: 30px;
      backdrop-filter: blur(14px);
      background: rgba(255,255,255,0.65);
      border-right: 1px solid rgba(0,0,0,0.05);
    }

    .case-sidebar h3 {
      margin-bottom: 20px;
      font-size: 1.2rem;
      font-weight: 700;
    }

    .case-link {
      padding: 14px 16px;
      border-radius: 14px;
      margin-bottom: 12px;
      cursor: pointer;
      transition: 0.35s;
      font-weight: 500;
    }

    .case-link:hover {
      background: rgba(99,102,241,0.1);
      transform: translateX(4px);
    }

    .case-link.active {
      background: linear-gradient(135deg, #6366f1, #8b5cf6);
      color: white;
      box-shadow: 0 12px 30px rgba(99,102,241,0.35);
    }

    /* Content */
    .case-content {
      padding: 60px;
    }

    .case-card {
      display: none;
      max-width: 900px;
      background: rgba(255,255,255,0.75);
      backdrop-filter: blur(18px);
      border-radius: 26px;
      padding: 40px;
      box-shadow: 0 25px 60px rgba(0,0,0,0.08);
      animation: fadeUp 0.5s ease;
    }

    .case-card.active {
      display: block;
    }

    @keyframes fadeUp {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    .case-card h2 {
      font-size: 2rem;
      margin-bottom: 10px;
    }

    .case-tags span {
      display: inline-block;
      padding: 6px 12px;
      margin: 6px 6px 10px 0;
      border-radius: 999px;
      background: #eef2ff;
      font-size: 0.8rem;
      font-weight: 500;
    }

    .case-section {
      margin-top: 18px;
      line-height: 1.6;
    }

    .case-section strong {
      color: #4f46e5;
    }

    /* Header */
    header.navbar {
      background: rgba(255,255,255,0.8);
      backdrop-filter: blur(12px);
    }

    /* Mobile */
    @media (max-width: 900px) {
      .case-layout {
        grid-template-columns: 1fr;
      }

      .case-sidebar {
        display: flex;
        overflow-x: auto;
        gap: 12px;
      }

      .case-link {
        white-space: nowrap;
      }

      .case-content {
        padding: 30px;
      }
    }
    .case-nav {
    display: flex;
    gap: 12px;
    flex-wrap: wrap;
}
.case-link {
  cursor: pointer;
  user-select: none;
  z-index: 10; /* ensure clickable */
  position: relative; /* needed for z-index */
}
.case-sidebar {
  pointer-events: auto;
}
@media (max-width: 900px) {
  .case-sidebar {
    display: flex;
    overflow-x: auto;
    pointer-events: auto; /* ensure clicks work */
  }
}
/* Mobile enhancements */
@media (max-width: 900px) {
  /* Sidebar sticky on top */
  .case-sidebar {
    position: sticky;
    top: 0;
    z-index: 50;
    padding: 16px;
    gap: 10px;
  }

  /* Make links more tappable */
  .case-link {
    padding: 10px 16px;
    font-size: 0.9rem;
    flex-shrink: 0;
  }

  /* Case content padding smaller */
  .case-content {
    padding: 20px;
  }

  /* Accordion style for sections */
  .case-section {
    border-top: 1px solid rgba(0,0,0,0.05);
    padding: 10px 0;
  }

  .case-section strong {
    display: block;
    cursor: pointer;
    margin-bottom: 6px;
  }

  .case-section p,
  .case-section ul {
    display: none;
    margin-top: 6px;
  }

  .case-section.active p,
  .case-section.active ul {
    display: block;
  }

  /* Sticky bottom navigation */
  .case-nav {
    position: sticky;
    bottom: 0;
    background: rgba(255,255,255,0.95);
    padding: 12px;
    justify-content: center;
    box-shadow: 0 -5px 12px rgba(0,0,0,0.1);
  }
}
.case-nav {
  position: relative;  /* normal flow */
  bottom: auto;
  margin-top: 40px;
  display: flex;
  justify-content: center;
  gap: 16px;
  flex-wrap: wrap;
  background: transparent; /* remove white background */
  padding: 0;             /* remove extra padding if any */
}

.case-nav .btn {
  background: linear-gradient(135deg, #6366f1, #8b5cf6);
  color: white;
  border: none;
  border-radius: 14px;
  padding: 12px 24px;
  font-weight: 600;
  cursor: pointer;
  box-shadow: 0 12px 30px rgba(99,102,241,0.35);
  transition: all 0.3s ease;
}

.case-nav .btn:hover {
  transform: translateY(-2px);
  box-shadow: 0 15px 35px rgba(99,102,241,0.4);
}

.case-nav .btn:active {
  transform: translateY(0px);
  box-shadow: 0 10px 25px rgba(99,102,241,0.3);
}

/* Mobile adjustments */
@media (max-width: 900px) {
  .case-nav {
    flex-direction: column;
    gap: 12px;
  }
  .case-nav .btn {
    width: 100%;
    text-align: center;
    padding: 14px 0;
  }
}
@media (max-width: 900px) {
  .case-layout {
    grid-template-columns: 1fr; /* single column layout */
  }

  .case-sidebar {
    display: block;
    position: relative !important;  /* ensure it’s not fixed or sticky */
    top: auto !important;           /* reset any top positioning */
    left: auto !important;          /* reset left if any */
    padding: 20px 0;
    background: rgba(255,255,255,0.65); /* frosted glass look */
    border-right: none;
    border-bottom: 1px solid rgba(0,0,0,0.05);
    max-height: none;   /* allow natural height */
    overflow: visible;  /* scroll with page */
  }

  .case-sidebar h3 {
    margin-bottom: 16px;
    padding-left: 20px;
  }

  .case-link {
    display: block;
    margin: 8px 0;
    padding: 12px 20px;
    border-radius: 14px;
    white-space: normal;
    width: 90%;
    transition: 0.35s;
  }

  .case-link:hover {
    transform: translateX(4px);
  }

  .case-content {
    padding: 20px;
  }
}

  </style>
</head>

<body>

<!-- HEADER -->
<!-- HEADER -->
<header class="navbar">
  <nav>
    <div class="logo">Portfolio</div>

    <div class="menu-toggle" id="mobile-menu">&#9776;</div>

    <div class="nav-links" id="nav-links">
      <a href="/" class="nav-item">Home</a>
      <a href="/#projects" class="nav-item">Projects</a>
      <a href="/#contact" class="nav-item">Contact</a>
    </div>
    <!-- Dark Mode toggle will be appended here by JS -->
  </nav>
</header>

<div class="case-layout">

  <!-- SIDEBAR -->
  <aside class="case-sidebar">
    <h3>Projects Case Study</h3>
    <div class="case-link active" data-target="spotify">Spotify Recommendation</div>
    <div class="case-link" data-target="ipl">IPL Dashboard</div>
    <div class="case-link" data-target="movie">Movie Recommendation</div>
    <div class="case-link" data-target="car">Car Price Prediction</div>
    <div class="case-link" data-target="cyber">Cyber Threat Detection</div>
  </aside>

  <!-- CONTENT -->
  <main class="case-content">

    <div class="case-card active" id="spotify">
  <h2>Spotify Real-Time Recommendation System</h2>
  <div class="case-tags">
    <span>Python</span><span>Flask</span><span>Spotify API</span><span>Recommendation Engine</span>
  </div>

  <div class="case-section">
    <strong>Overview:</strong>
    <p>This project is a real-time music recommendation system built using Python and the Spotify Web API. Its goal is to help users discover new music tailored to their listening preferences by analyzing their historical listening behavior and track audio features. By combining real-time user data with content-based recommendation techniques, this system demonstrates the practical application of data analytics and machine learning principles in the domain of music streaming.</p>
  </div>

  <div class="case-section">
    <strong>Problem Statement:</strong>
    <p>With millions of songs available on streaming platforms, users often struggle to find tracks that match their tastes. Standard playlists or charts do not capture individual preferences, making music discovery inefficient. This project aims to address that problem by creating a system that recommends songs dynamically based on the user's listening patterns and audio characteristics of tracks, enabling a personalized and engaging music experience.</p>
  </div>

  <div class="case-section">
    <strong>Data Sources & APIs:</strong>
    <p>The system relies on the Spotify Web API to fetch user data, including playlists, liked songs, recently played tracks, and audio features such as tempo, energy, danceability, acousticness, and valence. Audio features provide quantitative measures of musical characteristics, which are then used to calculate similarity between tracks and generate personalized recommendations.</p>
  </div>

  <div class="case-section">
    <strong>System Architecture & Workflow:</strong>
    <p>The application follows a structured workflow:</p>
    <ul>
      <li><strong>User Authentication:</strong> Users log in via Spotify OAuth 2.0, ensuring secure access to their personal listening data.</li>
      <li><strong>Data Retrieval:</strong> The system collects the user's recently played tracks, liked songs, and playlists along with their corresponding audio features.</li>
      <li><strong>Feature Processing:</strong> Each song is represented as a vector of audio features. These vectors are normalized to allow meaningful similarity comparisons.</li>
      <li><strong>Similarity Calculation:</strong> Using cosine similarity, the system measures how closely other tracks in the database match the user's preferred songs.</li>
      <li><strong>Recommendation Generation:</strong> Songs with the highest similarity scores are recommended to the user in real-time through a clean web interface.</li>
      <li><strong>Deployment:</strong> The app is deployed on a cloud platform using a `Procfile`, enabling web access and real-time interaction.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Features:</strong>
    <ul>
      <li>Secure user authentication via Spotify OAuth</li>
      <li>Retrieval of user playlists, liked tracks, and recently played songs</li>
      <li>Audio feature extraction for content-based similarity</li>
      <li>Real-time personalized song recommendations</li>
      <li>User-friendly web interface built with Flask</li>
      <li>Deployment-ready for cloud platforms (Heroku, Railway, etc.)</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Tech Stack:</strong>
    <p>The system was implemented using Python as the primary language, with Flask to handle web requests and build the interactive interface. Pandas and NumPy were used for data processing and feature calculations. Matplotlib or Seaborn can be used to visualize feature distributions or recommendation metrics. The Spotify Web API provides the necessary user and track data, and the system is deployment-ready with a `Procfile`.</p>
  </div>

  <div class="case-section">
    <strong>Challenges & Learnings:</strong>
    <p>Working with real-time API data posed challenges such as rate-limiting, token refresh handling, and ensuring efficient data processing for quick recommendations. Integrating user authentication securely required careful implementation of OAuth 2.0. Through this project, I enhanced my skills in API integration, backend web development, and real-time recommendation systems. It also strengthened my understanding of vector-based similarity measures and content-based recommendation logic.</p>
  </div>

  <div class="case-section">
    <strong>Key Insights:</strong>
    <ul>
      <li>Real-time analysis of user listening patterns allows for highly personalized recommendations.</li>
      <li>Audio feature-based similarity provides better suggestions than simple playlist matching.</li>
      <li>Integration with a web interface ensures immediate interaction and feedback for the user.</li>
      <li>Optimizing API calls and caching results can significantly improve system responsiveness.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Conclusion:</strong>
    <p>The Spotify Real-Time Recommendation System demonstrates the practical application of Python, web development, and data-driven recommendation algorithms in a real-world setting. It showcases the ability to integrate external APIs, process user data in real time, and deliver meaningful personalized recommendations. This project highlights my skills in backend development, data analytics, and interactive web deployment, making it an excellent addition to a technical portfolio.</p>
  </div>
  <div class="case-nav" style="margin-top: 30px; display: flex; gap: 12px; flex-wrap: wrap;">
  <button class="btn prevBtn">Previous</button>
  <a href="/" class="btn homeBtn">Back to Home</a>
  <button class="btn nextBtn">Next</button>
</div>
</div>


    <div class="case-card" id="ipl">
  <h2>IPL Data Analysis Dashboard</h2>
  <div class="case-tags">
    <span>Python</span><span>Pandas</span><span>Matplotlib</span><span>Seaborn</span>
  </div>

  <div class="case-section">
    <strong>Overview:</strong>
    <p>This project is an in-depth exploratory data analysis of the Indian Premier League (IPL) spanning the 2008–2019 seasons. The objective was to uncover meaningful patterns in team performance, player contributions, and match outcomes using historical cricket data. By transforming raw datasets into structured insights, the project demonstrates how data analytics can be applied to sports to support strategic understanding and decision-making.</p>
  </div>

  <div class="case-section">
    <strong>Problem Statement:</strong>
    <p>IPL generates a massive amount of match and ball-by-ball data each season, but raw statistics alone do not clearly explain performance trends or competitive advantages. The challenge was to analyze this data in a structured way to answer questions such as which teams have been the most consistent across seasons, how much influence the toss has on match outcomes, which players delivered the greatest impact in the T20 format, and how venues and match conditions affect scoring and results.</p>
  </div>

  <div class="case-section">
    <strong>Data Description:</strong>
    <p>The analysis uses historical IPL datasets containing match-level and ball-by-ball information from 2008 to 2019. Match-level data includes teams, venue, toss results, match winners, and result types, while ball-by-ball data provides detailed insights into runs, wickets, extras, and dismissal types. Combining these datasets enabled both high-level trend analysis and granular performance evaluation.</p>
  </div>

  <div class="case-section">
    <strong>Data Cleaning & Preparation:</strong>
    <p>Data preprocessing played a crucial role in this project. Missing values were handled, irrelevant columns were removed, and inconsistencies in team and player names were standardized across seasons. Matches were filtered to include only valid IPL seasons within the chosen timeframe. These steps ensured that the analysis was accurate, consistent, and reliable.</p>
  </div>

  <div class="case-section">
    <strong>Exploratory Data Analysis:</strong>
    <p>Initial exploration focused on understanding the overall structure of the data, including match distribution across seasons, scoring patterns, and result types. Visualizations were used to identify trends, outliers, and season-wise variations, forming the foundation for deeper analytical insights.</p>
  </div>

  <div class="case-section">
    <strong>Team Performance Analysis:</strong>
    <p>Team-wise performance was analyzed using metrics such as total matches played, wins, losses, and win percentages across seasons. This analysis highlights teams that consistently performed well over time as well as teams whose performance varied significantly between seasons. It also reveals how dominance in the league shifted as team strategies and compositions evolved.</p>
  </div>

  <div class="case-section">
    <strong>Toss Impact Analysis:</strong>
    <p>The project examines the relationship between toss results and match outcomes to evaluate whether winning the toss provides a strategic advantage. It also analyzes the impact of choosing to bat or bowl first. The findings show that while the toss can influence certain matches, it is not a decisive factor compared to overall team and player performance.</p>
  </div>

  <div class="case-section">
    <strong>Player Performance Analysis:</strong>
    <p><strong>Batting:</strong> Batting performance was evaluated using metrics such as total runs, average runs per season, strike rate, and boundary frequency. This analysis identifies top-performing and consistent batsmen, highlighting the importance of both aggressive scoring and reliability in the T20 format.</p>
    <p><strong>Bowling:</strong> Bowling performance was analyzed using wickets taken, economy rates, and dismissal patterns. The results highlight bowlers who consistently delivered under pressure and played a key role in controlling match outcomes.</p>
  </div>

  <div class="case-section">
    <strong>Venue-Based Insights:</strong>
    <p>Venue analysis was conducted to understand how different stadiums influence scoring patterns and match results. Certain venues were found to favor high-scoring matches, while others supported bowlers due to pitch behavior and ground dimensions. These insights demonstrate how external conditions shape match strategies.</p>
  </div>

  <div class="case-section">
    <strong>Key Insights:</strong>
    <ul>
      <li>A small group of teams demonstrated long-term dominance and consistency across IPL seasons.</li>
      <li>Winning the toss showed limited impact on overall match outcomes.</li>
      <li>Consistent individual performances from key batsmen and bowlers had a stronger influence on success than match conditions alone.</li>
      <li>Venue characteristics played a noticeable role in scoring trends and match results.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Tools & Technologies:</strong>
    <p>Python for data analysis, Pandas for data manipulation and preprocessing, Matplotlib & Seaborn for data visualization, and Jupyter Notebook/Python scripts for analysis workflow.</p>
  </div>

  <div class="case-section">
    <strong>Challenges & Learnings:</strong>
    <p>Working with large, multi-season datasets introduced challenges such as inconsistent naming conventions and missing values. The project strengthened skills in data cleaning, exploratory analysis, and analytical thinking, as well as the ability to extract insights from complex real-world datasets.</p>
  </div>

  <div class="case-section">
    <strong>Conclusion:</strong>
    <p>This IPL Data Analysis project showcases strong data analysis and storytelling skills, demonstrating the ability to turn raw sports data into meaningful insights. It highlights practical experience in handling large datasets, performing exploratory analysis, and presenting results in a clear and structured manner, making it a valuable addition to a data analytics or data science portfolio.</p>
  </div>
  <div class="case-nav" style="margin-top: 30px; display: flex; gap: 12px; flex-wrap: wrap;">
  <button class="btn prevBtn">Previous</button>
  <a href="/" class="btn homeBtn">Back to Home</a>
  <button class="btn nextBtn">Next</button>
</div>
</div>


    <div class="case-card" id="movie">
  <h2>Movie Recommender System</h2>
  <div class="case-tags">
    <span>Python</span><span>Flask</span><span>Recommendation</span><span>Machine Learning</span>
  </div>

  <div class="case-section">
    <strong>Overview:</strong>
    <p>This project is a Movie Recommender System built with Python that provides personalized movie suggestions based on users’ preferences. By integrating content similarity algorithms and collaborative filtering logic, it helps users discover movies that match their tastes from a large corpus of titles. This system showcases how recommendation engines can enhance user experience by generating meaningful suggestions similar to platforms like Netflix and IMDb.</p>
  </div>

  <div class="case-section">
    <strong>Problem Statement:</strong>
    <p>With thousands of movies available online, users often struggle to find relevant content. Static lists and top charts do not cater to individual tastes, leading to poor engagement. The goal of this project was to build a system that analyzes movie metadata and similarity patterns, and then recommends movies personalized for individual users.</p>
  </div>

  <div class="case-section">
    <strong>How It Works:</strong>
    <p>The system loads a precomputed movie similarity dataset (stored in compressed `.csv` files) and a dictionary of movie metadata (`movie_dict.pkl`). When a user interacts with the app, it computes recommendations by finding movies with the highest similarity scores relative to a selected title. The recommendation logic is driven by cosine similarity or related metrics between vectorized movie features — such as genres, ratings, and other metadata. This approach enables the system to produce relevant movie recommendations quickly and efficiently.</p>
  </div>

  <div class="case-section">
    <strong>Features:</strong>
    <ul>
      <li>Interactive movie recommendation interface powered by a Python web app.</li>
      <li>Precomputed similarity matrices for fast real‑time recommendations.</li>
      <li>Personalized suggestions based on selected movies and their locations in feature space.</li>
      <li>Lightweight web deployment using Flask and a `Procfile` for hosting.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Tech Stack:</strong>
    <p>The project was developed using Python, particularly leveraging libraries such as Pandas and NumPy for data manipulation and vector processing. The backend web interface is built with Flask, and the application is deployment‑ready using a `Procfile` configuration. The recommendation logic relies on precomputed similarity matrices stored in compressed CSV format. :contentReference[oaicite:1]{index=1}</p>
  </div>

  <div class="case-section">
    <strong>Implementation Details:</strong>
    <p>The repository includes several compressed similarity matrix files (`similarity_comp1.csv.gz`, etc.) and a Python script (`app.py`) that loads this data at runtime. The similarity matrices are likely generated by converting movie metadata into vectors and computing cosine similarity between feature representations. Using precomputed similarity allows the web app to return recommendations instantly without heavy computation during user interaction.</p>
  </div>

  <div class="case-section">
    <strong>Challenges & Learnings:</strong>
    <p>Developing a recommendation engine involved challenges such as handling high‑dimensional movie metadata, optimizing similarity computation for speed, and structuring the system for web deployment. Through this project, I strengthened my skills in data processing, algorithmic recommendation logic, and backend web application development.</p>
  </div>

  <div class="case-section">
    <strong>Impact & Insights:</strong>
    <p>By analyzing similarities between movies, this system enhances content discovery, increasing engagement and satisfaction for users exploring large movie catalogs. It demonstrates how machine learning techniques can be applied in a real‑world context for personalized recommendation tasks.</p>
  </div>

  <div class="case-section">
    <strong>Conclusion:</strong>
    <p>This Movie Recommender System outlines how data‑driven recommendation logic can be integrated into a dynamic web application. It highlights backend development using Flask, efficient use of similarity matrices for real‑time inference, and practical skills in building user‑centric features. The project is a valuable addition to a portfolio focused on machine learning and real‑world deployments.</p>
  </div>
  <div class="case-nav" style="margin-top: 30px; display: flex; gap: 12px; flex-wrap: wrap;">
  <button class="btn prevBtn">Previous</button>
  <a href="/" class="btn homeBtn">Back to Home</a>
  <button class="btn nextBtn">Next</button>
</div>
</div>


    <div class="case-card" id="car">
  <h2>Car Price Prediction</h2>
  <div class="case-tags">
    <span>Python</span><span>Flask</span><span>Machine Learning</span><span>Regression</span>
  </div>

  <div class="case-section">
    <strong>Overview:</strong>
    <p>This project is a machine learning‑powered car price prediction system that estimates the selling price of vehicles based on key features such as mileage, year of manufacture, brand, and other attributes. By training regression models on historical car sales data and deploying the model through a web interface, the application provides real‑time price predictions for users. This project demonstrates practical application of data science and machine learning techniques to a real‑world regression problem.</p>
  </div>

  <div class="case-section">
    <strong>Problem Statement:</strong>
    <p>With a wide range of car models and variations in condition, predicting fair market value for used cars can be challenging. Buyers and sellers often rely on rough estimates or subjective opinions, which can lead to underpricing or overpricing. The goal of this project was to build a model that uses historical data to learn relationships between car features and price, and then provide accurate predictions for unseen cars.</p>
  </div>

  <div class="case-section">
    <strong>Data Description:</strong>
    <p>The project uses datasets containing information on used cars, including features such as make, model, year, mileage, fuel type, and other relevant attributes. Multiple CSV files are included in the repository, and they are used for training, evaluating, and validating the machine learning model. A serialized trained model (`Model.pkl`) and a web interface (`app.py`) are provided for prediction and deployment. :contentReference[oaicite:0]{index=0}</p>
  </div>

  <div class="case-section">
    <strong>Data Preprocessing & Feature Engineering:</strong>
    <p>Data cleaning involved handling missing values, encoding categorical features (such as brand and fuel type), and scaling numerical features to ensure consistent ranges. This step was critical for improving model performance and reducing noise in the dataset. Feature engineering helped create additional meaningful variables, such as vehicle age or normalized mileage, which enhanced the model’s ability to learn patterns in pricing. :contentReference[oaicite:1]{index=1}</p>
  </div>

  <div class="case-section">
    <strong>Modeling Approach:</strong>
    <p>Regression models were trained to predict car prices based on the available features. Typical regression approaches include linear regression, Lasso regression, or other algorithms suitable for continuous target prediction. The model evaluation metrics — such as Mean Absolute Error (MAE) and R² score — were used to assess prediction quality and ensure the model generalizes well to unseen data. :contentReference[oaicite:2]{index=2}</p>
  </div>

  <div class="case-section">
    <strong>Web Deployment:</strong>
    <p>The trained model was deployed as a web application using a Python framework (Flask). The `app.py` script loads the serialized model (`Model.pkl`) and exposes a user‑friendly interface where users can input car details and receive a predicted price. A `Procfile` is included, which shows readiness for deployment on cloud platforms such as Heroku or Railway. :contentReference[oaicite:3]{index=3}</p>
  </div>

  <div class="case-section">
    <strong>Features:</strong>
    <ul>
      <li>Data preprocessing and feature transformation for accurate modeling.</li>
      <li>Machine learning regression model trained on historical car data.</li>
      <li>Real‑time price prediction via a Flask web app.</li>
      <li>Deployment readiness with a `Procfile` for cloud hosting.</li>
      <li>Model persistence using serialized `.pkl` file for quick inference.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Challenges & Learnings:</strong>
    <p>Tackling imbalanced or incomplete data required careful preprocessing and feature selection. Choosing the right regression model and fine‑tuning hyperparameters was essential for achieving reliable predictions. Integrating the machine learning model with a web interface deepened my understanding of end‑to‑end ML workflows — from training and evaluation to deployment.</p>
  </div>

  <div class="case-section">
    <strong>Key Insights:</strong>
    <ul>
      <li>Regression models can effectively estimate car prices when features are properly engineered and normalized.</li>
      <li>Handling categorical features thoughtfully impacts model performance significantly.</li>
      <li>Deploying machine learning models via web apps enhances their practical usefulness and accessibility.</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Conclusion:</strong>
    <p>The Car Price Prediction project demonstrates a complete machine learning solution — from data preprocessing and model training to real‑time deployment in a web application. It showcases skills in data science, regression modeling, backend development, and deployment tooling. This project is a strong addition to a data analytics or machine learning portfolio.</p>
  </div>
  <div class="case-nav" style="margin-top: 30px; display: flex; gap: 12px; flex-wrap: wrap;">
  <button class="btn prevBtn">Previous</button>
  <a href="/" class="btn homeBtn">Back to Home</a>
  <button class="btn nextBtn">Next</button>
</div>
</div>


    <div class="case-card" id="cyber">
  <h2>Cyber Threat Detection Suite</h2>
  <div class="case-tags">
    <span>Python</span><span>Machine Learning</span><span>Cybersecurity</span><span>Flask</span>
  </div>

  <div class="case-section">
    <strong>Overview:</strong>
    <p>This Cyber Threat Detection Suite is a machine learning–powered system designed to detect malicious network activity in real time. The goal is to provide a proactive cybersecurity tool that can analyze network traffic patterns and classify them into normal or potentially harmful behavior, supporting security operations and automated threat mitigation.</p>
  </div>

  <div class="case-section">
    <strong>Problem Statement:</strong>
    <p>Modern networks face a wide range of cyber threats including malware, denial‑of‑service (DoS) attacks, probes, and unauthorized access attempts. Traditional rule‑based security tools struggle to detect unknown or evolving threats. This project focuses on applying machine learning techniques to recognize patterns in network traffic that indicate cyber attacks, helping security teams respond faster and more accurately.</p>
  </div>

  <div class="case-section">
    <strong>Data Source & Preprocessing:</strong>
    <p>The system typically uses labeled network traffic datasets (e.g., protocols, packet features, and attack labels) to train models. Raw logs are preprocessed to handle missing values, encode categorical features, normalize numerical values, and balance classes so that the model learns effectively from both normal and malicious traffic examples.</p>
  </div>

  <div class="case-section">
    <strong>Modeling & Algorithms:</strong>
    <p>Machine learning models such as Random Forest, Support Vector Machines (SVM), Decision Trees, and ensemble learners are trained to classify traffic as benign or malicious based on labeled features. Supervised learning enables the system to differentiate between attack types and normal behavior. Models are evaluated using accuracy, precision, recall, and F1‑score metrics to ensure reliability.</p>
  </div>

  <div class="case-section">
    <strong>Real‑Time Detection & Deployment:</strong>
    <p>Once trained, the model is deployed behind a Flask API to serve real‑time predictions. Network traffic data is collected, transformed, and fed to the model, which returns classifications and confidence scores. This allows the system to issue alerts for suspected threats and support defensive actions in security operations.</p>
  </div>

  <div class="case-section">
    <strong>Key Features:</strong>
    <ul>
      <li>Preprocesses network traffic logs and prepares features for model training</li>
      <li>Trains machine learning models for threat classification</li>
      <li>Real‑time inference through a web API using Flask</li>
      <li>Generates confidence scores for predictions</li>
      <li>Visualizes attack categories and detection performance</li>
    </ul>
  </div>

  <div class="case-section">
    <strong>Tech Stack:</strong>
    <p>Python for data analysis and modeling, Flask for API development and deployment, Scikit‑learn or similar libraries for machine learning, and Pandas for data preprocessing. Visualization libraries can be used to create insight dashboards showing alerts, model performance, and traffic trends.</p>
  </div>

  <div class="case-section">
    <strong>Challenges & Learnings:</strong>
    <p>Handling imbalanced classes in cybersecurity datasets and avoiding overfitting were key challenges. Effective feature engineering and model selection were essential to improve detection accuracy. Integrating real‑time inference in a deployed environment required careful optimization to ensure low latency threat detection.</p>
  </div>

  <div class="case-section">
    <strong>Impact & Benefits:</strong>
    <p>The Cyber Threat Detection Suite demonstrates how machine learning can enhance traditional cybersecurity tools by improving the detection of complex attack patterns. It supports faster incident response, reduces false positives compared to static signature–based systems, and provides actionable insights that strengthen network defense capabilities.</p>
  </div>

  <div class="case-section">
    <strong>Conclusion:</strong>
    <p>This project showcases the application of Python, machine learning, and cybersecurity principles to build a threat detection system capable of recognizing malicious activities in network traffic. It highlights skills in data preprocessing, model training and evaluation, API deployment, and real‑time inference — making it a strong addition to a data science or cybersecurity portfolio.</p>
  </div>
  <div class="case-nav" style="margin-top: 30px; display: flex; gap: 12px; flex-wrap: wrap;">
  <button class="btn prevBtn">Previous</button>
  <a href="/" class="btn homeBtn">Back to Home</a>
  <button class="btn nextBtn">Next</button>
</div>

</div>


  </main>
</div>

<script>
const links = document.querySelectorAll(".case-link");
const cards = document.querySelectorAll(".case-card");
const prevBtns = document.querySelectorAll(".prevBtn");
const nextBtns = document.querySelectorAll(".nextBtn");

// Activate a project by ID
function activate(id) {
    links.forEach(l => l.classList.remove("active"));
    cards.forEach(c => c.classList.remove("active"));

    const link = document.querySelector(`[data-target="${id}"]`);
    const card = document.getElementById(id);

    if (link) link.classList.add("active");
    if (card) card.classList.add("active");
}

// Get index of currently active project
function getCurrentIndex() {
    return Array.from(cards).findIndex(c => c.classList.contains("active"));
}

// Sidebar links click
links.forEach(link => {
    link.addEventListener("click", () => {
        activate(link.dataset.target);
        history.replaceState(null, "", "#" + link.dataset.target);
    });
});

// Previous buttons
prevBtns.forEach(btn => {
    btn.addEventListener("click", () => {
        let index = getCurrentIndex();
        if (index > 0) {
            activate(cards[index - 1].id);
            history.replaceState(null, "", "#" + cards[index - 1].id);
        }
    });
});

// Next buttons
nextBtns.forEach(btn => {
    btn.addEventListener("click", () => {
        let index = getCurrentIndex();
        if (index < cards.length - 1) {
            activate(cards[index + 1].id);
            history.replaceState(null, "", "#" + cards[index + 1].id);
        }
    });
});

// Activate on page load based on URL hash
if (window.location.hash) {
    activate(window.location.hash.substring(1));
} else {
    activate(links[0].dataset.target); // default first project
}

</script>
<script>
  // Accordion for mobile case sections
  const sections = document.querySelectorAll('.case-card .case-section strong');
  sections.forEach(header => {
    header.addEventListener('click', () => {
      const section = header.parentElement;
      section.classList.toggle('active');
    });
  });
</script>


</body>
</html>